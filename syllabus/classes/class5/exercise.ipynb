{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from datasets import load_dataset\r\n",
    "import spacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Loading datasets\r\n",
    "dataset = load_dataset(\"health_fact\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset health_fact (C:\\Users\\louis\\.cache\\huggingface\\datasets\\health_fact\\default\\1.1.0\\99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19)\n",
      "100%|██████████| 3/3 [00:00<00:00, 77.13it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#spacy - Loading the english pipeline (small and big)\r\n",
    "nlp = spacy.load(\"en_core_web_sm\")\r\n",
    "#doc = nlp(...)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train = dataset[\"train\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#print(train[\"label\"]) #all labels\r\n",
    "#print(train[\"main_text\"]) #all main_text\r\n",
    "texts = train[\"main_text\"]\r\n",
    "print(type(texts))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "tf = []\r\n",
    "tf_term_freq = []\r\n",
    "for text in train[\"main_text\"][:10]:\r\n",
    "    doc = nlp(text)\r\n",
    "    #df = doc_freq2(train[\"main_text\"][:10]) #maybe throw away if a term only occurs in one text/doc\r\n",
    "    tf.append(doc)\r\n",
    "    tf_term_freq.append(term_freq(doc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "print(type(tf[0]))\r\n",
    "print(type(tf[0][0]))\r\n",
    "#print(tf_term_freq) dic"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#defining method of def fit(x, y) (all the training outside the model)\r\n",
    "# DictVectoriser from sklearn (0 stuff) - to make tf-idf into a vector (turns dict )\r\n",
    "#label vector has to be one hot encoded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "\r\n",
    "print(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'8': 3, '3': 8, 'k': 10, 'O': 5, '’': 10, 'D': 8, '1': 10, '7': 5, 'a': 10, '-': 10, 'E': 2, 'p': 10, 'y': 10, '&': 3, 'n': 10, 'q': 9, 'x': 10, 'd': 10, 'i': 10, 'P': 8, 'h': 10, '.': 10, 'J': 7, 'V': 5, 'j': 9, ':': 5, 'W': 6, 'o': 10, 'N': 6, 'Y': 1, '5': 6, 'l': 10, '\\xa0': 4, 'm': 10, 'r': 10, '—': 2, 'u': 10, 'f': 10, 'A': 8, 'F': 5, ',': 10, 'I': 8, '?': 2, 'e': 10, 'g': 10, '2': 10, 'K': 3, 'M': 8, ')': 8, 'L': 3, 'S': 8, 's': 10, 'c': 10, 'w': 10, 'z': 9, '0': 10, 'R': 6, 'b': 10, 't': 10, 'B': 9, '9': 7, 'U': 5, ' ': 10, 'G': 5, '/': 2, '(': 7, 'v': 10, '4': 6, '\"': 3, 'C': 6, 'T': 10, '…': 2, 'H': 6, '–': 2, '”': 6, '“': 6, '6': 6, '$': 5, '‘': 2, '%': 1, ';': 1, 'Z': 1, 'Q': 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#importing functions\r\n",
    "from frequencies import term_freq, doc_freq2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#tf-idf(t, d) = tf(t, d) * log(N/(df + 1))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "#print(dataset) #train, test, validataion\r\n",
    "\r\n",
    "#print(train.features)\r\n",
    "\r\n",
    "#print(train[0])\r\n",
    "#print(train[\"main_text\"][0], train[\"label\"][0])\r\n",
    "print(set(train[\"label\"])) #-1, 0, 1, 2, 3 = 5 output nodes"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0, 1, 2, 3, -1}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit ('nlp_env': venv)"
  },
  "interpreter": {
   "hash": "f20a2b0473630642730946317169bdea332e5675536504f1ca8796679a7e5286"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}