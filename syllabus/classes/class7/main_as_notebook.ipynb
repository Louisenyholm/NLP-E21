{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datasets import load_dataset\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conllpp (C:\\Users\\louis\\.cache\\huggingface\\datasets\\conllpp\\conllpp\\1.0.0\\04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2)\n",
      "100%|██████████| 3/3 [00:00<00:00, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']]\n",
      "[[3, 0, 7, 0, 0, 0, 7, 0, 0]]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# DATASET\n",
    "dataset = load_dataset(\"conllpp\")\n",
    "train = dataset[\"train\"]\n",
    "\n",
    "# inspect the dataset\n",
    "print(train[\"tokens\"][:1])\n",
    "print(train[\"ner_tags\"][:1])\n",
    "num_classes = train.features[\"ner_tags\"].feature.num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING EMBEDDINGS\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "from embedding import gensim_to_torch_embedding\n",
    "\n",
    "# convert gensim word embedding to torch word embedding\n",
    "embedding_layer, vocab = gensim_to_torch_embedding(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(400002, 50, padding_idx=400001)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer)\n",
    "#print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING A BATCH\n",
    "def tokens_to_idx(tokens, vocab=model.key_to_index):\n",
    "    \"\"\"\n",
    "    Ideas to understand this function:\n",
    "    - Write documentation for this function including type hints for each arguement and return statement\n",
    "    - What does the .get method do?\n",
    "    - Why lowercase?\n",
    "    \"\"\"\n",
    "    return [vocab.get(t.lower(), vocab[\"UNK\"]) for t in tokens]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f20a2b0473630642730946317169bdea332e5675536504f1ca8796679a7e5286"
  },
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit ('nlp_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
