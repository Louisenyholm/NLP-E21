{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Import Spacy\r\n",
    "import spacy\r\n",
    "import pandas as pd\r\n",
    "#import "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Loading the english pipeline (small and big)\r\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Paragraph from the ugly duckling\r\n",
    "txt = \"It was so beautiful out on the country, it was summer- the wheat fields were golden, the oats were green, and down among the green meadows the hay was stacked. There the stork minced about on his red legs, clacking away in Egyptian, which was the language his mother had taught him. Round about the field and meadow lands rose vast forests, in which deep lakes lay hidden. Yes, it was indeed lovely out there in the country.\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#with open('ugly_duckling.txt') as f:\r\n",
    " #   lines = f.readlines()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Running spacy pipeline on text\r\n",
    "doc = nlp(txt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def filter_pos(doc):\r\n",
    "\r\n",
    "    filtered_tokens = []\r\n",
    "\r\n",
    "    # Only include words of certain word-classes\r\n",
    "    for token in doc:\r\n",
    "        if token.pos_ in [\"AUX\", \"ADJ\", \"NOUN\", \"VERB\"]:\r\n",
    "        #if (token.pos_ == \"AUX\" or token.pos_ == \"ADJ\" or token.pos_ == \"NOUN\" or token.pos == \"VERB\"):\r\n",
    "            # Add the token in its lemma form to the list\r\n",
    "            filtered_tokens.append(token.lemma_)\r\n",
    "\r\n",
    "    return filtered_tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "filtred = filter_pos(doc)\r\n",
    "print(filtred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['be', 'beautiful', 'country', 'be', 'wheat', 'field', 'be', 'golden', 'oat', 'be', 'green', 'green', 'meadow', 'hay', 'be', 'stack', 'stork', 'mince', 'red', 'leg', 'clack', 'be', 'language', 'mother', 'have', 'teach', 'field', 'meadow', 'land', 'rise', 'vast', 'forest', 'deep', 'lake', 'lie', 'hidden', 'be', 'lovely', 'country']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Alternatively: use\r\n",
    "# pos_count = Counter([token.pos_ for token in doc])\r\n",
    "#pos_counts.values()\r\n",
    "#list(zip([j for j in pos_counts.keys()], [i/len(doc) for i in pos_counts.values()]))\r\n",
    "\r\n",
    "def calc_ratio(doc):\r\n",
    "    \r\n",
    "    # Calculate the total number of tokens in doc\r\n",
    "    n_tokens = len(doc)\r\n",
    "    \r\n",
    "    # Calculate ratio of verbs\r\n",
    "    n_verbs = []\r\n",
    "    for token in doc:\r\n",
    "        if (token.pos_ == \"AUX\" or token.pos_ == \"VERB\"):\r\n",
    "            n_verbs.append(token)  \r\n",
    "    n_verbs = len(n_verbs)\r\n",
    "    verb_ratio = n_verbs / n_tokens * 100\r\n",
    "    \r\n",
    "     # Calculate ratio of nouns\r\n",
    "    n_nouns = []\r\n",
    "    for token in doc:\r\n",
    "        if (token.pos_ == \"NOUN\"):\r\n",
    "            n_nouns.append(token)  \r\n",
    "    n_nouns = len(n_nouns)\r\n",
    "    noun_ratio = n_nouns / n_tokens * 100\r\n",
    "    \r\n",
    "    # Calculate ratio of adjectives\r\n",
    "    n_adj = []\r\n",
    "    for token in doc:\r\n",
    "        if (token.pos_ == \"ADJ\"):\r\n",
    "            n_adj.append(token)  \r\n",
    "    n_adj = len(n_adj)\r\n",
    "    adj_ratio = n_adj / n_tokens * 100\r\n",
    "    \r\n",
    "    # Make dataframe\r\n",
    "    data = {\"Ratio of Verbs\": [round(verb_ratio,2)],\r\n",
    "            \"Ratio of Nouns\": [round(noun_ratio,2)],\r\n",
    "            \"Ratio of Adjectives\": [round(adj_ratio,2)]}\r\n",
    "    \r\n",
    "    df = pd.DataFrame(data)\r\n",
    "    \r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "calc_ratio(doc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of Verbs</th>\n",
       "      <th>Ratio of Nouns</th>\n",
       "      <th>Ratio of Adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.73</td>\n",
       "      <td>17.98</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratio of Verbs  Ratio of Nouns  Ratio of Adjectives\n",
       "0           15.73           17.98                10.11"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Last\r\n",
    "\r\n",
    "#Tokens have the attribute .head (corresponding to the parsing dependencies)\r\n",
    "#Indices for token = token.i (subtract token.i for two words)\r\n",
    "#Get the ABSOLUTE value (to avoid negative values)\r\n",
    "#Use either 8 or 9 (including all words or all relations) - whether you include the word \"admitted\" or not"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit ('nlp_env': venv)"
  },
  "interpreter": {
   "hash": "f20a2b0473630642730946317169bdea332e5675536504f1ca8796679a7e5286"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}