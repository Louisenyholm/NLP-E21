{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Import Spacy\r\n",
    "import spacy\r\n",
    "import pandas as pd\r\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Loading the english pipeline (small and big)\r\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# Paragraph from the ugly duckling\r\n",
    "txt = \"It was so beautiful out on the country, it was summer- the wheat fields were golden, the oats were green, and down among the green meadows the hay was stacked. There the stork minced about on his red legs, clacking away in Egyptian, which was the language his mother had taught him. Round about the field and meadow lands rose vast forests, in which deep lakes lay hidden. Yes, it was indeed lovely out there in the country.\"\r\n",
    "txt_da = \"Der var så dejligt ude på landet; det var sommer, kornet stod gult, havren grøn, høet var rejst i stakke nede i de grønne enge, og der gik storken på sine lange, røde ben og snakkede ægyptisk, for det sprog havde han lært af sin moder. Rundt om ager og eng var der store skove, og midt i skovene dybe søer; jo, der var rigtignok dejligt derude på landet!\"\r\n",
    "txt_dog = \"dog\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#with open('ugly_duckling.txt') as f:\r\n",
    " #   lines = f.readlines()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# Running spacy pipeline on text\r\n",
    "doc = nlp(txt)\r\n",
    "doc_da = nlp(txt_da)\r\n",
    "doc_dog = nlp(txt_dog)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def filter_pos(doc):\r\n",
    "\r\n",
    "    filtered_tokens = []\r\n",
    "\r\n",
    "    # Only include words of certain word-classes\r\n",
    "    for token in doc:\r\n",
    "        if token.pos_ in [\"AUX\", \"ADJ\", \"NOUN\", \"VERB\"]:\r\n",
    "        #if (token.pos_ == \"AUX\" or token.pos_ == \"ADJ\" or token.pos_ == \"NOUN\" or token.pos == \"VERB\"):\r\n",
    "            # Add the token in its lemma form to the list\r\n",
    "            filtered_tokens.append(token.lemma_)\r\n",
    "\r\n",
    "    return filtered_tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "filtred = filter_pos(doc)\r\n",
    "print(filtred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['be', 'beautiful', 'country', 'be', 'wheat', 'field', 'be', 'golden', 'oat', 'be', 'green', 'green', 'meadow', 'hay', 'be', 'stack', 'stork', 'mince', 'red', 'leg', 'clack', 'be', 'language', 'mother', 'have', 'teach', 'field', 'meadow', 'land', 'rise', 'vast', 'forest', 'deep', 'lake', 'lie', 'hidden', 'be', 'lovely', 'country']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#Frida's alternative to the below:\r\n",
    "#counts number of cases of the different class types (pos)\r\n",
    "pos_counts = Counter([token.pos_ for token in doc])\r\n",
    "# Counter is a container that will hold the count of each of the elements present in the container\r\n",
    "    \r\n",
    "# For class type tag (pos) and count (both from above), take the pos tag and the count divided by length to get freq\r\n",
    "pos_list = [(pos, count/len(doc)) for pos, count in pos_counts.items()]\r\n",
    "#outputs as a list of tuples dict(list_of_tuples) to convert to dictionary\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'dict'>\n",
      "{'PRON': 0.06741573033707865, 'AUX': 0.06741573033707865, 'ADV': 0.0898876404494382, 'ADJ': 0.10112359550561797, 'ADP': 0.10112359550561797, 'DET': 0.12359550561797752, 'NOUN': 0.1797752808988764, 'PUNCT': 0.12359550561797752, 'X': 0.011235955056179775, 'VERB': 0.0898876404494382, 'CCONJ': 0.02247191011235955, 'PROPN': 0.011235955056179775, 'INTJ': 0.011235955056179775}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "#preparing a function for class 4 in the same format\r\n",
    "def term_freq(tokens) -> dict:\r\n",
    "    \"\"\"\r\n",
    "    Takes in a list of tokens (str) and return a dictionary of term frequency of each token\r\n",
    "    (doc = a list of tokens)\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    #counts number of cases of the different class types (pos)\r\n",
    "    pos_counts = Counter([token.pos_ for token in doc])\r\n",
    "\r\n",
    "    # For class type tag (pos) and count (both from above),\r\n",
    "    # take the pos tag and the count divided by length to get freq\r\n",
    "    tf_lst = [(pos, count/len(doc)) for pos, count in pos_counts.items()]\r\n",
    "    #convert the list of tuples to a dictionary\r\n",
    "    tf_dict = dict(tf_lst)\r\n",
    "\r\n",
    "    return tf_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#testing the function\r\n",
    "term_freq(doc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'PRON': 0.06741573033707865,\n",
       " 'AUX': 0.06741573033707865,\n",
       " 'ADV': 0.0898876404494382,\n",
       " 'ADJ': 0.10112359550561797,\n",
       " 'ADP': 0.10112359550561797,\n",
       " 'DET': 0.12359550561797752,\n",
       " 'NOUN': 0.1797752808988764,\n",
       " 'PUNCT': 0.12359550561797752,\n",
       " 'X': 0.011235955056179775,\n",
       " 'VERB': 0.0898876404494382,\n",
       " 'CCONJ': 0.02247191011235955,\n",
       " 'PROPN': 0.011235955056179775,\n",
       " 'INTJ': 0.011235955056179775}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "\r\n",
    "def calc_ratio(doc):\r\n",
    "    \r\n",
    "    # Calculate the total number of tokens in doc\r\n",
    "    n_tokens = len(doc)\r\n",
    "    \r\n",
    "    # Calculate ratio of verbs\r\n",
    "    n_verbs = []\r\n",
    "    for token in doc:\r\n",
    "        if (token.pos_ == \"AUX\" or token.pos_ == \"VERB\"):\r\n",
    "            n_verbs.append(token)  \r\n",
    "    n_verbs = len(n_verbs)\r\n",
    "    verb_ratio = n_verbs / n_tokens * 100\r\n",
    "    \r\n",
    "     # Calculate ratio of nouns\r\n",
    "    n_nouns = []\r\n",
    "    for token in doc:\r\n",
    "        if (token.pos_ == \"NOUN\"):\r\n",
    "            n_nouns.append(token)  \r\n",
    "    n_nouns = len(n_nouns)\r\n",
    "    noun_ratio = n_nouns / n_tokens * 100\r\n",
    "    \r\n",
    "    # Calculate ratio of adjectives\r\n",
    "    n_adj = []\r\n",
    "    for token in doc:\r\n",
    "        if (token.pos_ == \"ADJ\"):\r\n",
    "            n_adj.append(token)  \r\n",
    "    n_adj = len(n_adj)\r\n",
    "    adj_ratio = n_adj / n_tokens * 100\r\n",
    "    \r\n",
    "    # Make dataframe\r\n",
    "    data = {\"Ratio of Verbs\": [round(verb_ratio,2)],\r\n",
    "            \"Ratio of Nouns\": [round(noun_ratio,2)],\r\n",
    "            \"Ratio of Adjectives\": [round(adj_ratio,2)]}\r\n",
    "    \r\n",
    "    df = pd.DataFrame(data)\r\n",
    "    \r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "calc_ratio(doc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of Verbs</th>\n",
       "      <th>Ratio of Nouns</th>\n",
       "      <th>Ratio of Adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.73</td>\n",
       "      <td>17.98</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratio of Verbs  Ratio of Nouns  Ratio of Adjectives\n",
       "0           15.73           17.98                10.11"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# prepping some input for the function below\r\n",
    "doc_EN_DA_dog = [doc, doc_da, doc_dog]\r\n",
    "print(type(doc_EN_DA_dog))\r\n",
    "print(doc_EN_DA_dog)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n",
      "[It was so beautiful out on the country, it was summer- the wheat fields were golden, the oats were green, and down among the green meadows the hay was stacked. There the stork minced about on his red legs, clacking away in Egyptian, which was the language his mother had taught him. Round about the field and meadow lands rose vast forests, in which deep lakes lay hidden. Yes, it was indeed lovely out there in the country., Der var så dejligt ude på landet; det var sommer, kornet stod gult, havren grøn, høet var rejst i stakke nede i de grønne enge, og der gik storken på sine lange, røde ben og snakkede ægyptisk, for det sprog havde han lært af sin moder. Rundt om ager og eng var der store skove, og midt i skovene dybe søer; jo, der var rigtignok dejligt derude på landet!, dog]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# Preparing another function for class 4 in line with this\r\n",
    "\r\n",
    "#doc_freq(t) = occurrence of t in document\r\n",
    "\r\n",
    "def doc_freq(doc_lst) -> dict:\r\n",
    "    \"\"\"\r\n",
    "    Takes in a list of documents which each is a list of tokens (str) and return a dictionary of frequencies for each token over all the documents. E.g. {\"Aarhus\": 20, \"the\": 2301, ...}\r\n",
    "    \"\"\"\r\n",
    "    #empty list (can only append to lists, not to counters)\r\n",
    "    all_counters_lst = []\r\n",
    "\r\n",
    "    #Iterating through docs\r\n",
    "    for doc in doc_lst:\r\n",
    "        #append to list a counter with frequencies of pos in each doc\r\n",
    "        all_counters_lst.append(Counter([token.pos_ for token in doc]))\r\n",
    "\r\n",
    "    #Empty counter (.update works on counters, not lists)\r\n",
    "    all_counters = Counter()\r\n",
    "\r\n",
    "    #iterating thorugh counters, updating (=adding)\r\n",
    "    for counter in all_counters_lst:\r\n",
    "        all_counters.update(counter)\r\n",
    "\r\n",
    "    return all_counters"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "#testing the function above\r\n",
    "doc_freq(doc_lst = doc_EN_DA_dog)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'PRON': 8,\n",
       "         'AUX': 6,\n",
       "         'ADV': 9,\n",
       "         'ADJ': 9,\n",
       "         'ADP': 13,\n",
       "         'DET': 11,\n",
       "         'NOUN': 39,\n",
       "         'PUNCT': 24,\n",
       "         'X': 3,\n",
       "         'VERB': 13,\n",
       "         'CCONJ': 2,\n",
       "         'PROPN': 33,\n",
       "         'INTJ': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Last\r\n",
    "\r\n",
    "#Tokens have the attribute .head (corresponding to the parsing dependencies)\r\n",
    "#Indices for token = token.i (subtract token.i for two words)\r\n",
    "#Get the ABSOLUTE value (to avoid negative values)\r\n",
    "#Use either 8 or 9 (including all words or all relations) - whether you include the word \"admitted\" or not"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit ('nlp_env': venv)"
  },
  "interpreter": {
   "hash": "f20a2b0473630642730946317169bdea332e5675536504f1ca8796679a7e5286"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}